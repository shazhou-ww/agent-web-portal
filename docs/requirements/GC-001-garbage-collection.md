# GC-001: 垃圾回收机制

> 优先级：P0 - 必须完成

## 背景

CAS 存储基于不可变性设计。用户"删除"文件实际上是 commit 一个新的 collection（不包含该 entry），旧的 collection 和被"删除"的 file/chunk 节点仍然存在于 S3。

随着时间推移，孤立节点（orphaned nodes）会越来越多，导致：
- 存储成本增加
- 配额计算不准确
- 潜在的安全/合规问题

## 需求

实现垃圾回收机制，清理不再被任何 commit 引用的节点。

## 设计问题

### 1. 触发时机

| 选项 | 优点 | 缺点 |
|------|------|------|
| 定时任务（如每天凌晨） | 简单，可预测 | 不够及时，需要调度系统 |
| 用户主动触发 | 用户可控 | 依赖用户操作 |
| 存储阈值触发 | 自动化 | 实现复杂 |
| 写入时惰性清理 | 无需额外调度 | 增加写入延迟 |

**待决定**：选择哪种触发方式？

### 2. GC 粒度

| 选项 | 说明 |
|------|------|
| 按 realm | 每个用户空间独立 GC |
| 全局 | 整个系统一起 GC（需考虑跨 realm 共享） |

**待决定**：是否需要支持跨 realm 共享节点？如果是，GC 需要全局视角。

### 3. 算法选择

| 算法 | 优点 | 缺点 |
|------|------|------|
| 标记-清除 | 准确，无需维护计数 | 需要遍历整个 DAG |
| 引用计数 | 实时，增量 | 需要维护计数，循环引用问题（DAG 无此问题） |

**待决定**：选择哪种算法？

### 4. 可达性判定

从哪些 root 开始标记可达节点？

- `commits` 表中的所有 root key
- 还需要包含什么？（如进行中的 ticket 写入？）

**待决定**：可达性的定义边界。

### 5. 安全窗口

问题：用户上传了 chunk，还没来得及创建 file 节点和 commit，此时 GC 运行会删掉这些 chunk。

解决方案选项：
- 基于时间戳：只清理 N 小时之前的孤立节点
- 基于 Ticket：有活跃可写 Ticket 引用的节点不清理
- 两阶段：先标记为"待删除"，下次 GC 再真正删除

**待决定**：安全窗口策略。

### 6. 执行方式

| 选项 | 说明 |
|------|------|
| 同步阻塞 | 简单，但可能很慢 |
| 后台异步 | 不阻塞业务，但需要状态追踪 |
| 分批处理 | 大数据量友好 |

**待决定**：执行方式。

## 相关数据结构

- `commits` 表：所有 commit 的 root key
- `ownership` 表：realm 拥有的所有 key + 元数据
- S3 `cas/` 前缀：实际存储

## API 设计（草案）

```typescript
// 管理员接口
POST /admin/gc/start
GET /admin/gc/status
GET /admin/gc/history

// 或者作为后台任务，无需暴露 API
```

## 验收标准

- [ ] 孤立节点能被正确识别
- [ ] 正在使用的节点不会被误删
- [ ] GC 过程中系统正常可用
- [ ] 有 GC 执行日志/统计
- [ ] 配额在 GC 后正确更新

## 决策记录

| 日期 | 决策 | 原因 |
|------|------|------|
| - | - | - |
